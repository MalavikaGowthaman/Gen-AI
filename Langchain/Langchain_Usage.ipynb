{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Langchain**"
      ],
      "metadata": {
        "id": "3z3ULwDcj9ZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain is a library designed to make it easy to build applications using large language models (LLMs) by combining several common components into a cohesive framework. The main idea behind LangChain is to enable developers to create applications that can interact with data, generate responses, and perform reasoning tasks in a structured way. Here’s a breakdown of how it works in simple terms:\n",
        "\n",
        "1. **Chains**: LangChain is based on the concept of \"chains,\" which are sequences of actions that can include calling a language model, retrieving information, or using external data sources. Chains let you build a sequence of steps to answer complex questions or perform tasks, like summarizing documents or answering questions based on specific documents.\n",
        "\n",
        "2. **Agents**: Agents are like intelligent assistants that can decide which tools to use to answer a question. In LangChain, agents can use tools like search engines or APIs to gather information before responding. For example, if someone asks about the weather, the agent might use a weather API to get the answer.\n",
        "\n",
        "3. **Memory**: LangChain allows models to \"remember\" past interactions, so it can handle conversations with context over multiple interactions. This feature is useful for creating conversational AI applications that need to recall previous messages or topics in a chat.\n",
        "\n",
        "4. **Document Loaders and Indexes**: LangChain can load documents from various sources (like PDFs, websites, or databases) and index them to make searching easier. This makes it possible to retrieve specific information from a large dataset, like finding key information in a series of research papers or company documents.\n",
        "\n",
        "5. **Retrievers**: When using LangChain with large datasets, retrievers help pull the most relevant parts of the data based on user questions. This is especially useful for applications that need precise answers from large knowledge bases or document collections.\n",
        "\n",
        "LangChain’s flexibility allows it to support different language models and APIs, making it useful for various tasks, from customer service bots to document search engines."
      ],
      "metadata": {
        "id": "T5eUAI-NkB1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- GitHub: https://github.com/hwchase17/langchain\n",
        "- Docs: https://python.langchain.com/v0.2/docs/introduction/\n",
        "\n",
        "### Overview:\n",
        "- Installation\n",
        "- LLMs\n",
        "- Prompt Templates\n",
        "- Chains\n",
        "- Agents and Tools\n",
        "- Memory\n",
        "- Document Loaders\n",
        "- Indexes"
      ],
      "metadata": {
        "id": "1XOHvUT1kGpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installation**"
      ],
      "metadata": {
        "id": "KaiwpTJHkOGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOk78mF5j9LR",
        "outputId": "e17bce51-ee14-4b3d-e7f1-9e666660db7a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.15)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.142)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain)\n",
            "  Downloading langchain_core-0.3.18-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.18-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain_community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.15\n",
            "    Uninstalling langchain-core-0.3.15:\n",
            "      Successfully uninstalled langchain-core-0.3.15\n",
            "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-core-0.3.18 langchain_community-0.3.7 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LLM** - Large Language Model\n",
        "\n",
        "The basic building block of LangChain is a Large Language Model which takes text as input and generates more text.\n",
        "\n",
        "Suppose we want to generate a company name based on the company description, so we will first initialize an OpenAI wrapper. In this case, since we want the output to be more random, we will intialize our model with high temprature.\n",
        "\n",
        "The temperature parameter adjusts the randomness of the output. Higher values like 0.7 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n",
        "\n",
        "temperature value--> how creative we want our model to be\n",
        "0 ---> temperature it means model is  very safe it is not taking any bets.\n",
        "1 --> it will take risk it might generate wrong output but it is very creative"
      ],
      "metadata": {
        "id": "gryQl6rxlBS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A generic interface for all LLMs. See all LLM providers: https://python.langchain.com/api_reference/"
      ],
      "metadata": {
        "id": "aZXe8NktlXOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. LLM**"
      ],
      "metadata": {
        "id": "gOFrHamkaZcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Langchain using LLM(Openai)**"
      ],
      "metadata": {
        "id": "0gZcALt1koQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlsLg7zZkfxo",
        "outputId": "4e89fcaa-6a1c-4dbc-9cbc-a471b397fc27"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1"
      ],
      "metadata": {
        "id": "a8C1-Mt1l0eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "OPENAI_API_KEY = \"********************"\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "RWsb_Sjgl-9r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature = 1)\n",
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa1tokDFkwAD",
        "outputId": "dfc6d708-fc97-4e0c-8761-e07ff83921ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-66e8ce87d2c9>:2: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = OpenAI(temperature = 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OpenAI(client=<openai.resources.completions.Completions object at 0x7a79979b57b0>, async_client=<openai.resources.completions.AsyncCompletions object at 0x7a799662d840>, temperature=1.0, model_kwargs={}, openai_api_key='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', openai_proxy='', logit_bias={})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm(\"What is the capital of India?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "H_vS7cKNl5wF",
        "outputId": "8ddf62d9-3020-4e98-d907-49513b3f2753"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-c856e6a1bab0>:1: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  llm(\"What is the capital of India?\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nNew Delhi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I am planning to start a IT company based on AI can you  suggest a name for me?\"\n",
        "llm(query)"
      ],
      "metadata": {
        "id": "mv6drmiUnXEd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b1d3f7d8-53da-4d9e-a85c-3210c73d11d1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  \\n\\n1. AI Innovations Co.\\n2. Neural Nexus Technologies\\n3. TuringTech Solutions\\n4. Intelligent Minds IT\\n5. AdaptIQ Solutions\\n6. SynapseTech Group\\n7. Insightful AI Inc.\\n8. PreciseAI Solutions\\n9. Digital Brain Technologies\\n10. ThinkBotix Technologies'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.predict(query))# can use predict for getting the output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDza80QsqH-8",
        "outputId": "74613749-b623-4085-d5f9-9078967f9d0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-a069933612cf>:1: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(llm.predict(query))# can use predict for getting the output\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. AIgenius Solutions\n",
            "2. NeuralTech Innovations\n",
            "3. MindByte Technologies\n",
            "4. SmartMind Solutions\n",
            "5. IntelliLogic Solutions\n",
            "6. AImpact Innovations\n",
            "7. FutureAI Systems\n",
            "8. CognitiveTech Solutions\n",
            "9. Brainwave Technologies\n",
            "10. AIverse Solutions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y69_GjPrFjF",
        "outputId": "bc49c9fc-99ba-4341-a3d9-cb0fa7ba7fe3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "AIgenius Tech Solutions \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = \"Give a answer in a short way: Suggest the ways to improve English pronounciation and to learn new vocubulary\"\n",
        "print(llm.predict(query1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovjBWqx5rP53",
        "outputId": "5417cb98-f0f8-45b6-a4b9-4a44e45ff8f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Practice speaking with native English speakers or fluent speakers.\n",
            "2. Listen to English podcasts, audiobooks, or videos to expose yourself to different accents and pronunciation.\n",
            "3. Use pronunciation tools or apps to help identify and correct any mispronunciations.\n",
            "4. Expand your vocabulary by reading, watching movies or TV shows, and actively looking up new words.\n",
            "5. Keep a vocabulary journal to write down and review new words regularly.\n",
            "6. Practice speaking with correct intonation and stress to improve your overall pronunciation.\n",
            "7. Utilize online resources, such as online courses or language learning websites, to actively learn and practice new vocabulary.\n",
            "8. Take a pronunciation or accent reduction class to receive personalized instruction and feedback.\n",
            "9. Record yourself speaking and listen back to identify areas for improvement.\n",
            "10. Stay consistent and dedicated in your practice and learning to see progress in your English pronunciation and vocabulary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = \"Translate to tamil: How are you?\"\n",
        "print(llm.invoke(query2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9F-YMgWrb8W",
        "outputId": "5f6bf52f-914e-4f7f-acd8-e750949939bf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "நீங்கள் எப்படி இருக்கிறீர்கள்? (Nīṅkaḷ eppaṭi irukkiṟīrkaḷ?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Hugging face**"
      ],
      "metadata": {
        "id": "CBShN07JafDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Langchain using Hugging face**"
      ],
      "metadata": {
        "id": "20297WmRs3Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zOuTihKs2-Y",
        "outputId": "af7901a9-7016-4144-d481-b8c8d5d991b6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
      ],
      "metadata": {
        "id": "tFce3YXKVA5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example -1"
      ],
      "metadata": {
        "id": "u3GJmpLJXtO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub"
      ],
      "metadata": {
        "id": "TDX15FeRsl45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceHub(repo_id = \"google/flan-t5-large\", model_kwargs = {\"temperature\":0.1})\n",
        "prompt = \"Who is the prime minister of India?\"\n",
        "llm(prompt)\n"
      ],
      "metadata": {
        "id": "HIy5KfmjtKgk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "5e33b615-3db5-4c58-d25d-1a46314a07f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-e6647a20ad63>:1: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
            "  llm = HuggingFaceHub(repo_id = \"google/flan-t5-large\", model_kwargs = {\"temperature\":0.1})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'narendra modi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceHub(repo_id = \"google/flan-t5-large\", model_kwargs = {\"temperature\":0.1})\n",
        "prompt = \"What is the capital of Tamilnadu?\"\n",
        "llm(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8eFs1DhbUl0l",
        "outputId": "b94303ba-53d4-4286-a371-8418f5e1ec37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chennai'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceHub(repo_id = \"google/flan-t5-large\", model_kwargs = {\"temperature\":0.1})\n",
        "llm(\"translate English to french: How old are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ulBFORTuXE6k",
        "outputId": "3007dfc6-d87a-4322-98ca-9e8023357a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Comment vieux êtes-vous?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example-2"
      ],
      "metadata": {
        "id": "H6Yk9YjPXxsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub\n",
        "llm = HuggingFaceHub(repo_id = \"google/flan-t5-large\", model_kwargs = {\"temperature\":0.1})\n",
        "name = llm.predict(\"Suggest a list of 10 best tourist place to visit in Canada\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI-klt7wXQGe",
        "outputId": "0241f94c-e6a7-4002-83d9-ce0719f9187a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Canada's capital\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub\n",
        "llm = HuggingFaceHub(repo_id = \"google/flan-t5-large\", model_kwargs = {\"temperature\":0.1})\n",
        "name = llm.invoke(\"Suggest a list of names for naming a restaurant\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUUZqqpqYS1x",
        "outputId": "3201d66a-de39-4ce2-a0d7-0a5eda21fbae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tao, tao chinese, tao \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Using Prompt Template**"
      ],
      "metadata": {
        "id": "Dg6CkuP6apzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompt Template**\n",
        "\n",
        "Currently in the above applications we are writing an entire prompt, if you are creating a user directed application then this is not an ideal case\n",
        "\n",
        "LangChain faciliates prompt management and optimization.\n",
        "\n",
        "Normally when you use an LLM in an application, you are not sending user input directly to the LLM. Instead, you need to take the user input and construct a prompt, and only then send that to the LLM.\n",
        "\n",
        "In many Large Language Model applications we donot pass the user input directly to the Large Language Model, we add the user input to a large piece of text called prompt template"
      ],
      "metadata": {
        "id": "NrvDnYOQZCiW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example -1"
      ],
      "metadata": {
        "id": "wffdvW4ka9fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input = ['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
        ")\n",
        "prompt_template_name.format(cuisine = \"Italian\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pXx_20PYYnjd",
        "outputId": "95fc6dae-7c49-429d-8ba3-5ddb6b342044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I want to open a restaurant for Italian food. Suggest a fancy name for this.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "prompt = PromptTemplate(\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
        ")\n",
        "prompt.format(cuisine = \"Indian\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3fP_O-abcQ_m",
        "outputId": "a587b965-135c-4c16-ede7-696f0aba0af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I want to open a restaurant for Indian food. Suggest a fancy name for this.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example - 2"
      ],
      "metadata": {
        "id": "x0wWx0xKbvZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "prompt = PromptTemplate.from_template(\"What is the capital of {country}?\")\n",
        "prompt.format(country = \"India\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "73uHn5MObmd_",
        "outputId": "f0532316-15b7-48c8-ee49-902434e36a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the capital of India?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Chains**"
      ],
      "metadata": {
        "id": "O7sc8aa-hFTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chains**\n",
        "\n",
        "Combine LLMs and Prompts in multi-step workflows\n",
        "\n",
        "Now as we have the  **model**:\n",
        "\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "\n",
        "\n",
        "and the **Prompt Template**:\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
        "\n",
        "\n",
        "prompt.format(product=\"colorful socks\")\n",
        "\n",
        "\n",
        "Now using Chains we will link together model and the PromptTemplate and other Chains\n",
        "\n",
        "\n",
        "The simplest and most common type of Chain is LLMChain, which passes the input first to Prompt Template and then to Large Language Model\n",
        "\n",
        "LLMChain is responsible to execute the PromptTemplate, For every PromptTemplate we will specifically have an LLMChain"
      ],
      "metadata": {
        "id": "anbvA_8KhRnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example -1"
      ],
      "metadata": {
        "id": "IMNrwgDShlIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing openai\n",
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature=0.9)\n"
      ],
      "metadata": {
        "id": "AoaM2Z49cHbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting prompt temp\n",
        "from langchain.prompts import PromptTemplate\n",
        "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
        "prompt.format(product=\"coffee\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8fQdhkFIhvtK",
        "outputId": "164cf955-c68d-4780-8c10-e5750408360b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is a good name for a company that makes coffee'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whatever input text i am giving that will get assigned to this particular variable that is **product**"
      ],
      "metadata": {
        "id": "jEt8VGJciUTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# llm chain\n",
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm,prompt = prompt)\n",
        "\n",
        "reponse=chain.run(\"coffee\")\n",
        "print(reponse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF24gajqiQQC",
        "outputId": "65914a83-1dcb-47a0-8aef-1a6044df486e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. \"Roast & Brew Co.\"\n",
            "2. \"Morning Buzz Coffee Co.\"\n",
            "3. \"Bean & Ground Co.\"\n",
            "4. \"Caffeine Creations\"\n",
            "5. \"Perk Up Co.\"\n",
            "6. \"Java Joe's\"\n",
            "7. \"Brewtiful Coffee Co.\"\n",
            "8. \"The Daily Grind Co.\"\n",
            "9. \"Bean There, Done That\"\n",
            "10. \"Espresso Euphoria Co.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example - 2"
      ],
      "metadata": {
        "id": "Bc1YTyxbjEZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature = 0.9)"
      ],
      "metadata": {
        "id": "qvNMZYTeiuo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt = PromptTemplate(\n",
        "    input =[\"country\"],\n",
        "    template = \"What is the capitial of a {country}\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnQpgiYUjRoo",
        "outputId": "c69a049b-3700-4ff3-aab1-46938958424a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['country'] input_types={} partial_variables={} template='What is the capitial of a {country}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm,prompt=prompt)\n",
        "response = chain.run(\"India\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoUc-BApjjOr",
        "outputId": "feb62a7f-53e3-462d-91f7-f69a9f2ab0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The capital of India is New Delhi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm,prompt=prompt,verbose = True)\n",
        "response = chain.run(\"India\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYP8r2pWjyih",
        "outputId": "caa68e0d-58a1-499e-c219-0ae21776df2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWhat is the capitial of a India\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "The capital of India is New Delhi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **Can we combine Multiple PromptTemplates, We will try to combine Multiple PromptTemplates**\n",
        "*   **The output from the first PromptTemplate is passed to the next PromptTemplate as input**\n",
        "*   **To combine the Chain and  to set a sequence for that we use SimpleSequentialChain**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VIQtL2TukiQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simple Sequential Chain**"
      ],
      "metadata": {
        "id": "i6uzgk5ykxGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature = 0.9)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables = [\"country\"],\n",
        "    template = \"What is the capital of a {country}?\"\n",
        ")\n",
        "\n",
        "country_chain = LLMChain(llm=llm,prompt = prompt)\n",
        "\n",
        "prompt_list = PromptTemplate(\n",
        "    input_variables = [\"capital\"],\n",
        "    template = \"What is the largest city in {capital}?\"\n",
        ")\n",
        "\n",
        "capital_chain = LLMChain(llm=llm,prompt = prompt_list)"
      ],
      "metadata": {
        "id": "-1his1eNkXTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "chain = SimpleSequentialChain(chains = [country_chain,capital_chain])\n",
        "response = chain.run(\"India\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAt4yON0lplP",
        "outputId": "3ad0e3e0-4c89-48b2-f948-71ce15ee7d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The largest city in New Delhi is also New Delhi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There is a issue with SimpleSequentialChain it only shows last input information**\n",
        "\n",
        "**To show the entire information i will use SequentialChain**"
      ],
      "metadata": {
        "id": "6ekY_kFBnJV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SequentialChain**"
      ],
      "metadata": {
        "id": "xg3TLTUVnPM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature = 0.9)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables = [\"country\"],\n",
        "    template = \"What is the capital of a {country}?\"\n",
        ")\n",
        "\n",
        "country_chain = LLMChain(llm=llm,prompt = prompt, output_key = \"capital\") # need to give output key\n",
        "\n",
        "prompt_list = PromptTemplate(\n",
        "    input_variables = [\"capital\"],\n",
        "    template = \"What is the largest city in {capital}?\"\n",
        ")\n",
        "\n",
        "capital_chain = LLMChain(llm=llm,prompt = prompt_list,output_key = \"largest city\" )"
      ],
      "metadata": {
        "id": "OEIQjMvpnYjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "chain = SequentialChain(\n",
        "    chains = [country_chain,capital_chain],\n",
        "    input_variables = [\"country\"],\n",
        "    output_variables=['capital','largest city'])\n",
        "\n",
        "response = chain({\"country\":\"India\"})\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx9LAcs6nbj6",
        "outputId": "f24fdde5-5d9d-4e88-cec4-d54f037f1a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'country': 'India',\n",
              " 'capital': '\\n\\nNew Delhi',\n",
              " 'largest city': '\\n\\nNew Delhi is a metropolitan area, and thus does not have a specific \"largest city.\" Some of the largest and most populous areas within New Delhi include Delhi, Gurugram, Noida, and Faridabad.'}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Agents and Tools**"
      ],
      "metadata": {
        "id": "LU1dvhVQAWQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done.\n",
        "\n",
        "\n",
        "When used correctly agents can be extremely powerful. In order to load agents, you should understand the following concepts:\n",
        "\n",
        "- Tool: A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains.\n",
        "- LLM: The language model powering the agent.\n",
        "- Agent: The agent to use."
      ],
      "metadata": {
        "id": "XpgJy5zuAmrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agent is a very powerful concept in LangChain\n",
        "\n",
        "For example I have to travel from Dubai to Canada, I type this in ChatGPT\n",
        "\n",
        "---> Give me  two flight options from Dubai to Canada on September 1, 2024 | ChatGPT will not be able to answer because has knowledge till\n",
        "September 2021\n",
        "\n",
        "\n",
        "ChatGPT plus has Expedia Plugin, if we enable this plugin it will go to Expedia Plugin and will try to pull information about Flights & it will show the information"
      ],
      "metadata": {
        "id": "bRZnL7jmAojg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SerpApi is a real-time API to access Google search results."
      ],
      "metadata": {
        "id": "JnEjsTXrAu-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wikipedia and llm-math tool"
      ],
      "metadata": {
        "id": "sOH1NTCkAwQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "Q7MLpT4LoSa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684bf9aa-0019-4419-9675-0fbf44dcbf82"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=e0e253ab61a210b4d3a07ce716cfeb5c71b90dc2a8238b661aac6376a63dd6f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools, initialize_agent, AgentType\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "_Mj-UBRuA3Kk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature =0)"
      ],
      "metadata": {
        "id": "0jRzjm5MBxoz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"wikipedia\",\"llm-math\"],llm = llm)\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    # verbose=True\n",
        ")\n",
        "\n",
        "agent.run(\"Which company is the top company in IT in 2024\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sBhKTpiECChf",
        "outputId": "49bdc3a2-383a-4acb-d9e3-2b348d85b7be"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ITC Limited is the top IT company in India for 2024.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"What is the capital of Tamilnadu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Y9Bsv1zzCcqd",
        "outputId": "77bb695c-a4c9-4faa-84fd-386f86c795f7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The capital of Tamilnadu is Chennai.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Memory**"
      ],
      "metadata": {
        "id": "B-Rvl2-GGd4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chatbot application like ChatGPT, like to make a memory update for getting previous question."
      ],
      "metadata": {
        "id": "XmXliCjgGlbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI\n",
        "llm = OpenAI(temperature =0)"
      ],
      "metadata": {
        "id": "zhiGK4AJEc1Y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables = [\"country\"],\n",
        "    template = \"What is the capital of a {country}?\"\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "yPgCBlKaG3dw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm = llm, prompt = prompt)\n",
        "response = chain.run(\"Canada\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdZhtD87HEXZ",
        "outputId": "c03adc1b-c684-4e77-cc6e-bbc61af042fa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-2d15a595381a>:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm = llm, prompt = prompt)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The capital of Canada is Ottawa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.run(\"India\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvfgF3HDHW6E",
        "outputId": "965545b2-f586-4e88-cec0-96539e6c80d6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The capital of India is New Delhi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.memory"
      ],
      "metadata": {
        "id": "DddwyiPSHcPr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(chain.memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwP1JSa8He_a",
        "outputId": "c83616b7-2eb3-48ef-c53b-298589b5d502"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConversationBufferMemory\n",
        "\n",
        "We can attach memory to remember the past convo"
      ],
      "metadata": {
        "id": "rj5pyQTEHhqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "chain = LLMChain(llm=llm,prompt=prompt,memory=memory)\n",
        "response = chain.run(\"India\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbps2BviHgYp",
        "outputId": "b51c9dfe-886e-4b5a-f853-6171e61cab93"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-f715931ce2ab>:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The capital of India is New Delhi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.run(\"Canada\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMPv5VlnH_p8",
        "outputId": "5fa6c7dc-fb7a-4251-ab99-ff71ae371d03"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The capital of Canada is Ottawa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.run(\"America\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtNuDnMlIGSQ",
        "outputId": "d16fc377-6242-4995-c249-f6b8f8174217"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The capital of America is Washington, D.C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-1CjHOUIJGj",
        "outputId": "04c6516d-d2fb-49b3-b46c-d6417ee0c24e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: India\n",
            "AI: \n",
            "\n",
            "The capital of India is New Delhi.\n",
            "Human: Canada\n",
            "AI: \n",
            "\n",
            "The capital of Canada is Ottawa.\n",
            "Human: London\n",
            "AI: \n",
            "\n",
            "London does not have a capital as it is already a city and the capital of England.\n",
            "Human: AMerica\n",
            "AI: \n",
            "\n",
            "There is no country called \"AMerica,\" so it does not have a capital. The capital of the United States of America is Washington, D.C.\n",
            "Human: America\n",
            "AI: \n",
            "\n",
            "The capital of America is Washington, D.C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above buffershows all the conversation which are given"
      ],
      "metadata": {
        "id": "8wq6oB6eIZIG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ConversationChain"
      ],
      "metadata": {
        "id": "gfed87utIgi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversation buffer memory goes growing endlessly\n",
        "\n",
        "Just remember last 5 Conversation Chain\n",
        "\n",
        "Just remember last 10-20 Conversation Chain"
      ],
      "metadata": {
        "id": "cAvzGg1uIkpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "memory = ConversationChain(llm = OpenAI(temperature =0.7))\n",
        "print(memory.prompt.template)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZKdHM4cIThJ",
        "outputId": "fc9e5c01-d75a-4864-e4ac-8715c5fcc9cc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-5c1cb2a68e20>:2: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  memory = ConversationChain(llm = OpenAI(temperature =0.7))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.run(\"Who won the first world cup of Cricket?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "A9Sum5tjI-uB",
        "outputId": "7a3246ee-d966-4ee6-fdea-c751b2776b57"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The first world cup of Cricket was won by the West Indies in 1975. The tournament was held in England and it featured eight teams. The West Indies defeated Australia in the final by 17 runs. The player of the tournament was Clive Lloyd from the West Indies, who scored 102 runs in the final. This was the start of a dominant era for the West Indies in cricket, as they went on to win the next two world cups in 1979 and 1983.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.run(\"What is the capital of India?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "k4Z0uOGIJKCe",
        "outputId": "cf4666b4-cbd4-488d-a230-a5932efc252c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The capital of India is New Delhi. It is located in the northern part of India and has a population of over 11 million people. New Delhi was officially declared the capital of India in 1911, replacing Kolkata. It is home to important government buildings, such as the Rashtrapati Bhavan (the official residence of the President of India) and the Parliament House. It is also a major cultural and economic center, with many historical monuments and bustling markets.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.run(\"Who is the captain of that wining team?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "ZeiizRBEJQGQ",
        "outputId": "d0590c31-a104-42ba-98e2-b77f47324e51"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The captain of the West Indies team that won the first world cup of Cricket in 1975 was Clive Lloyd. He was a left-handed middle-order batsman and a medium-pace bowler. Lloyd was known for his strong leadership skills and was considered one of the greatest captains in the history of cricket. He also led the West Indies to victory in the 1979 and 1983 world cups. Lloyd retired from cricket in 1985 and was inducted into the ICC Cricket Hall of Fame in 2009. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.run(\"how much is 5+90?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Zkp3r0YbJX_m",
        "outputId": "b17f27e1-9e3d-42b1-8698-1357df407877"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  I am still unable to provide an answer as I do not have the ability to perform mathematical calculations. Is there anything else I can assist you with?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(memory.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNLBA7q6JgiE",
        "outputId": "6d02f851-1bc5-4900-e2e3-86e5f0182c01"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Who won the first world cup of Cricket?\n",
            "AI:  The first world cup of Cricket was won by the West Indies in 1975. The tournament was held in England and it featured eight teams. The West Indies defeated Australia in the final by 17 runs. The player of the tournament was Clive Lloyd from the West Indies, who scored 102 runs in the final. This was the start of a dominant era for the West Indies in cricket, as they went on to win the next two world cups in 1979 and 1983.\n",
            "Human: What is the capital of India?\n",
            "AI:  The capital of India is New Delhi. It is located in the northern part of India and has a population of over 11 million people. New Delhi was officially declared the capital of India in 1911, replacing Kolkata. It is home to important government buildings, such as the Rashtrapati Bhavan (the official residence of the President of India) and the Parliament House. It is also a major cultural and economic center, with many historical monuments and bustling markets.\n",
            "Human: Who is the captain of that wining team?\n",
            "AI:  The captain of the West Indies team that won the first world cup of Cricket in 1975 was Clive Lloyd. He was a left-handed middle-order batsman and a medium-pace bowler. Lloyd was known for his strong leadership skills and was considered one of the greatest captains in the history of cricket. He also led the West Indies to victory in the 1979 and 1983 world cups. Lloyd retired from cricket in 1985 and was inducted into the ICC Cricket Hall of Fame in 2009. \n",
            "Human: 5+90\n",
            "AI:  I'm an AI and do not possess the ability to perform mathematical calculations. I apologize for the inconvenience. Is there anything else I can assist you with?\n",
            "Human: how much is 5+90\n",
            "AI:  I apologize for the confusion. As an AI, I am not capable of performing mathematical calculations. Is there anything else I can help you with?\n",
            "Human: how much is 5+90?\n",
            "AI:   I am still unable to provide an answer as I do not have the ability to perform mathematical calculations. Is there anything else I can assist you with?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "6N8mQcqEKz_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=3)\n",
        "\n",
        "convo = ConversationChain(\n",
        "    llm=OpenAI(temperature=0.7),\n",
        "    memory=memory\n",
        ")\n",
        "convo.run(\"Who won the first cricket world cup?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "p1jZsLxUJyN6",
        "outputId": "ccc49809-6f1b-45bb-cd7e-bf7cf5a703e5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The first cricket world cup was won by England in 1975. The final match was played between England and Australia at Lord's Cricket Ground in London. England won by 17 runs. Did you know that the first cricket world cup was also known as the Prudential Cup, as it was sponsored by the Prudential Assurance Company? \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "xJIDvALuLS0f",
        "outputId": "33539bfa-d37b-4c43-eed2-b8768c314f1d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 5+5 is equal to 10. Did you know that the concept of addition has been around since ancient times, with evidence of it being used in ancient civilizations such as Egypt and Mesopotamia? It is a fundamental mathematical operation that is used in everyday tasks, from counting money to calculating distances.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who was the captain of the winning team?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "gPR22KZfLWCe",
        "outputId": "a70dc44a-369c-4ee4-8487-3521d7281550"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The captain of the winning team for the first cricket world cup was Mike Brearley for England. He was a right-handed batsman and a right-arm medium pace bowler. He also went on to captain England in 31 Test matches. Interestingly, Brearley was not the original captain for the team, but was asked to take over the role just six weeks before the start of the tournament.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(convo.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDKNjdnpLXge",
        "outputId": "e7811c4d-9564-4a06-c5f1-0bce3d238d22"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Who won the first cricket world cup?\n",
            "AI:  The first cricket world cup was won by England in 1975. The final match was played between England and Australia at Lord's Cricket Ground in London. England won by 17 runs. Did you know that the first cricket world cup was also known as the Prudential Cup, as it was sponsored by the Prudential Assurance Company? \n",
            "Human: How much is 5+5?\n",
            "AI:  5+5 is equal to 10. Did you know that the concept of addition has been around since ancient times, with evidence of it being used in ancient civilizations such as Egypt and Mesopotamia? It is a fundamental mathematical operation that is used in everyday tasks, from counting money to calculating distances.\n",
            "Human: Who was the captain of the winning team?\n",
            "AI:  The captain of the winning team for the first cricket world cup was Mike Brearley for England. He was a right-handed batsman and a right-arm medium pace bowler. He also went on to captain England in 31 Test matches. Interestingly, Brearley was not the original captain for the team, but was asked to take over the role just six weeks before the start of the tournament.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Document Loader**"
      ],
      "metadata": {
        "id": "mx4MyhTgUq4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCZYtUmtLbZe",
        "outputId": "1ba9abfc-4990-4a44-d37e-9363127273e9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"/content/MalavikaGowthaman.pdf\")\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "8vO80vKHUvbA"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk1H6NKgU6BQ",
        "outputId": "82db7cea-60e6-4ae4-d2c8-f049c73696b2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/MalavikaGowthaman.pdf', 'page': 0}, page_content='Malavika Gowthaman [Portfolio]                                      \\nAI Engineer | Data Scientist | Masters in Data Science                                                                           \\nScarborough, Ontario, Canada                                                                                                                     \\nData Scientist and AI Engineer with 5 years of experience in data collection, model development, and deployment, specializing  in \\ndeep learning, machine learning, and neural networks. Strong background in IT, computer science, mathematics, and data analytics, \\nwith expertise in large language models (LLMs). \\nWORK EXPERIENCE \\nHope Artificial Intelligence Pvt Ltd - AI Engineer                                                                                        04/24 – Present \\n\\uf0b7 Developing a healthcare app to improve disease diagnosis accuracy by 20% through data collection and analysis of over 10,000 \\npatient records. Implementing machine learning models for predictive analysis, aiming to reduce diagnostic time by 30%.Focusing on \\noptimizing performance and providing real-time insights for better decision-making in healthcare. \\n\\uf0b7 Built a Random Forest model for personal loan eligibility prediction with 99% accuracy, collaborating with cross -functional teams \\nincluding finance and product management to deploy the model in a web interface.(GitHub.com). \\n\\uf0b7 Developed FitTrack, a Streamlit web app with Python and Google’s Gen AI for BMI calculation and personalized recommendation, \\nfeaturing robust error handling and secure API management.(GitHub.com) \\nHCL Technologies - Senior Software Developer in Data Science                      09/22 – 04/24  \\n\\uf0b7 Developed Python code for document classification, invoice processing, and language detection with 95% accuracy, using MLflow  for \\nmodel tracking. \\n\\uf0b7 Created P2DTM BIM 7D dashboards and led machine learning research on Azure ML, improving forecasting accuracy by 20%. \\n\\uf0b7 Visualized call flow trends using PowerBI and DAX, analyzing over 50,000 records, and automated data extraction for 150+ entr ies \\nwith Python and Pyppeteer. Collaborated with clients to deliver tailored software solutions that met specific business requirements. \\nXecutesmart Technologies - Data Scientist                                                                                                        06/21 – 09/22 \\n\\uf0b7 Developed and deployed disease prediction models using Python, TensorFlow, Keras, a nd ML algorithms, achieving nearly 90% \\naccuracy. Conducted sentiment analysis on airline data and visualized insights from Twitter comments.  \\n\\uf0b7 Analyzed reservation system data with Talend and Power BI, creating dashboards. Designed dimensional data models for banking \\nprojects and executed complex SQL queries and ETL processes using Informatica.  \\n\\uf0b7 Grroom - Software Developer                         12/19 – 05/21 \\n\\uf0b7 Gained foundational experience as an intern, developed and optimized complex SQL queries, also created interactive dashboards as a \\nfull-time Software Developer, which improved data reporting efficiency by 30%.  \\n\\uf0b7 Worked on data collection, labelling, and pre-processing in the fashion industry, handled and prepared data from more than 10,000 \\nimages to enhance model accuracy and performance. \\n \\nPROJECT EXPERIENCE \\n\\uf0b7 Created a Flask web app for doctors to predict diseases using patient data, enabling early diagnostics. Utilized feature engi neering and \\nGridSearchCV to optimize the machine learning model for accurate predictions.( GitHub.com) \\n\\uf0b7 Developed a smoking detection model using PyTorch YOLOv5, achieved 90% accuracy, and documented the process in a Jupyter \\nnotebook for future enhancements.(GitHub.com) \\n\\uf0b7 Designed a deep learning model using TensorFlow and VGG19 for chest cancer classification based on CT scan images. Utilized \\nDocker and GitHub Actions for CI/CD pipelines and deployed the front-end application for this project on the AWS \\nplatform.(GitHub.com) \\n\\uf0b7 Engineered a  TensorFlow-based CNN model with 99% accuracy for face mask detection in images and real-time videos, also \\nimplemented rigorous data pre-process to improve the data quality and validation techniques.(GitHub.com) \\n\\uf0b7 Launched an Information Retrieval System Streamlit web application focused on 3 types of documents using Langchain, and \\nsuccessfully launched on AWS EC2 for scalable access.(GitHub.com) \\n\\uf0b7 Implemented a house price prediction model and created a web application that was deployed in a GCP Docker container for real -\\ntime use. (GitHub.com) \\n\\uf0b7 Developed a model using YOLOv8 for real-time detection of helmets and number plates from live video feeds. (GitHub.com) \\n\\uf0b7 Created a model for industrial safety gear detection using YOLOv8, capable of detecting safety gear in real -time. (GitHub.com) \\n \\nEDUCATION \\n\\uf0b7 Masters of Technology in Data Science  | Anna University, Tamil Nadu, India                                             06/2021 \\n\\uf0b7 Bachelor of Engineering in Electronics and Communications Engineering| Anna University, Tamil Nadu, India                      05/2019  \\n \\nSKILLS \\nProgramming: Python, Cloud: AWS, GCP, Azure ML, AI & ML: Deep Learning, Machine Learning, NLP, TensorFlow, PyTorch, \\nVisualization tools: Power BI, Tableau, CI/CD & Tools: Docker, GitHub Actions, MLflow, Kubernetes, Databases: Oracle SQL. \\n \\nCERTIFICATION \\nMicrosoft: Data Science Associate, Coursera: Deep Learning.ai Specialization, Data Analytics using ML & AI.  \\nEmail:malavikag115@gmail.com \\nPhone: + 1 647 446 1531 \\nLinkedIn.com | GitHub.com ')]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2s4B0VXVU6hj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
